{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "\n",
    "from PIL import Image \n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir ='/home/dongsung/Downloads/caltech-256-image-dataset/256_ObjectCategories/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dongsung/Downloads/caltech-256-image-dataset/256_ObjectCategories/001.ak47\n",
      "98\n",
      "['001_0089.jpg', '001_0033.jpg']\n",
      "['001_0001.jpg', '001_0002.jpg']\n"
     ]
    }
   ],
   "source": [
    "# image data file handling\n",
    "\n",
    "object_categories = listdir(data_dir)\n",
    "object_categories.sort()\n",
    "# for i in range(len(object_categories)):\n",
    "#     print (object_categories[i])\n",
    "\n",
    "category_dir = join(data_dir,object_categories[0])\n",
    "print(category_dir)\n",
    "\n",
    "# store full path\n",
    "onlyfiles = [f for f in listdir(category_dir) if isfile(join(category_dir, f))]\n",
    "\n",
    "print(len(onlyfiles))\n",
    "print (onlyfiles[:2])\n",
    "\n",
    "onlyfiles.sort()\n",
    "print (onlyfiles[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "saved_dir ='/home/dongsung/Downloads/caltech-256-image-dataset/temp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slpit data (train,val)\n",
    "# val has 20 images from each class of train dataset\n",
    "def split_data(data_dir,saved_dir):\n",
    "    for i in range(len(object_categories)):\n",
    "        # dataset\n",
    "        category_dir = join(data_dir,object_categories[i])\n",
    "        # read files\n",
    "        onlyfiles = [f for f in listdir(category_dir) if isfile(join(category_dir, f))]\n",
    "        onlyfiles.sort()\n",
    "        \n",
    "        # copy traing_data\n",
    "        train_saved_dir=saved_dir+'train_no_resizing/'\n",
    "        for image_file in onlyfiles[:-20]:\n",
    "            shutil.copy(join(category_dir,image_file), join(train_saved_dir,image_file)) \n",
    "            \n",
    "        # copy validation data\n",
    "        \n",
    "        val_saved_dir = saved_dir+'val/'\n",
    "        for image_file in onlyfiles[-20:]:\n",
    "            shutil.copy(join(category_dir,image_file), join(val_saved_dir,image_file)) \n",
    "        \n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data(data_dir,saved_dir)\n",
    "#print(onlyfiles)\n",
    "# print(onlyfiles[-20:])\n",
    "# print(onlyfiles[:-20])\n",
    "# val_saved_dir = saved_dir+'/val/'\n",
    "# print (val_saved_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25468 5139 30607\n",
      "['001_0098.jpg', '002_0078.jpg', '002_0079.jpg']\n",
      "[    0     1     2 ... 25465 25466 25467]\n",
      "[18026 21009  9244 ... 10397  2164 10072]\n",
      "192_0026.jpg 192\n",
      "228_0018.jpg 228\n",
      "103_0084.jpg 103\n",
      "009_0021.jpg 9\n",
      "136_0066.jpg 136\n"
     ]
    }
   ],
   "source": [
    "# storing image as index and filename(including the path)\n",
    "# data_set has index and filename\n",
    "# label has index and lable\n",
    "train_data=[]\n",
    "train_labels=[]\n",
    "val_data=[]\n",
    "val_labels=[]\n",
    "\n",
    "train_saved_dir ='/home/dongsung/Downloads/caltech-256-image-dataset/temp/train_no_resizing'\n",
    "val_saved_dir ='/home/dongsung/Downloads/caltech-256-image-dataset/temp/val'\n",
    "\n",
    "train_image_files = [f for f in listdir(train_saved_dir) if isfile(join(train_saved_dir, f))]\n",
    "val_image_files = [f for f in listdir(val_saved_dir) if isfile(join(val_saved_dir, f))]\n",
    "train_image_files.sort()\n",
    "val_image_files.sort()\n",
    "print(len(train_image_files), len(val_image_files), np.add(len(train_image_files),len(val_image_files)))\n",
    "print(val_image_files[19:22])\n",
    "\n",
    "# parsing logics for getting a label from a file name\n",
    "\n",
    "# def readimages(data_dir,data_list,label_list):\n",
    "#     for i in range(len(object_categories)):\n",
    "#         # dataset\n",
    "#         category_dir = join(data_dir,object_categories[i])\n",
    "#         #print(category_dir)\n",
    "#         onlyfiles = [f for f in listdir(category_dir) if isfile(join(category_dir, f))]\n",
    "#         onlyfiles.sort()\n",
    "#         num_images_per_class = len(onlyfiles)\n",
    "#         print(i+1, num_images_per_class)\n",
    "#         # handling dataset\n",
    "#         for j in range(len(onlyfiles)):\n",
    "#             train_data.append(onlyfiles[j])\n",
    "#             train_labels.append(i+1)\n",
    "            \n",
    "# handling data, label from\n",
    "train_data_images = [f for f in listdir(train_saved_dir) if isfile(join(train_saved_dir, f))]\n",
    "train_data_images.sort()\n",
    "\n",
    "for image_file in train_data_images:\n",
    "    train_data.append(image_file)\n",
    "    label = int(image_file.split('_')[0])\n",
    "    train_labels.append(label)\n",
    "    \n",
    "val_data_images = [f for f in listdir(val_saved_dir) if isfile(join(val_saved_dir, f))]\n",
    "val_data_images.sort()\n",
    "    \n",
    "for image_file in val_data_images:\n",
    "    val_data.append(image_file)\n",
    "    label = int(image_file.split('_')[0])\n",
    "    val_labels.append(label)    \n",
    "\n",
    "\n",
    "arr_indexes = np.arange(len(train_data))\n",
    "print(arr_indexes)\n",
    "# shuffle\n",
    "np.random.shuffle(arr_indexes)\n",
    "print(arr_indexes)\n",
    "\n",
    "for i in arr_indexes[0:5]:\n",
    "    print(train_data[i],train_labels[i])\n",
    "\n",
    "\n",
    "# index handlig for data_provider\n",
    "# batch_x = np.zeros((current_batch_size,) + self.image_shape, dtype=K.floatx())\n",
    "#         batch_logits = np.zeros((current_batch_size, self.num_class), dtype=K.floatx())\n",
    "#         grayscale = self.color_mode == 'grayscale'\n",
    "#         # build batch of image data\n",
    "#         for i, j in enumerate(index_array):\n",
    "#             fname = self.filenames[j]\n",
    "#             img = load_img(os.path.join(self.directory, fname),\n",
    "#                            grayscale=grayscale,\n",
    "#                            target_size=self.target_size)\n",
    "#             x = img_to_array(img, data_format=self.data_format)\n",
    "#             x = self.image_data_generator.random_transform(x)\n",
    "#             x = self.image_data_generator.standardize(x)\n",
    "#             batch_x[i] = x\n",
    "            batch_logits[i] = self.logits_dict[fname]\n",
    "    \n",
    "    \n",
    "    for i, label in enumerate(self.classes[index_array]):\n",
    "                batch_y[i, label] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data, labels, batch_size=32, input_shape=(299,299,3),n_classes=10, shuffle=True):\n",
    "    \n",
    "    num_data = len(data)\n",
    "    arr_indexes = np.arange(num_data)\n",
    "    \n",
    "    # shuffle\n",
    "    if shuffle:\n",
    "        np.random.shuffle(arr_indexes)\n",
    "    \n",
    "    num_batch = num_data/batch_size\n",
    "    if (num_data/batch_size) > 0:\n",
    "        num_batch = num_batch+1\n",
    "    \n",
    "    batch_x = np.zeros((batch_size,)+ input_shape)\n",
    "    batch_y = np.zeros((batch_size,)+ n_classes)\n",
    "    \n",
    "    offset=0\n",
    "    end =0\n",
    "    \n",
    "    for i in range(num_batch):\n",
    "        \n",
    "        offset=end\n",
    "        end=batch_size+offsest\n",
    "        if end > num_data:\n",
    "            end = num_data\n",
    "\n",
    "        batch_arr_indexes = arr_indexes[offset:end]\n",
    "        \n",
    "        # preparing the batch and yield batches\n",
    "        for i, idx in enumerate(batch_arr_indexes):\n",
    "            fname = data[idx]\n",
    "            # image load from index\n",
    "                   \n",
    "            # data resizing\n",
    "    #         img = load_img(os.path.join(self.directory, fname),\n",
    "    #                            grayscale=grayscale,\n",
    "    #                            target_size=self.target_size)\n",
    "\n",
    "            label = labes[idx]\n",
    "            batch_y[i, label]= 1\n",
    "\n",
    "        yield batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[7 1 9 6 2 5 0 3 4 8]\n",
      "(32, 299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "indexes = np.arange(10)\n",
    "print(indexes)\n",
    "np.random.shuffle(indexes)\n",
    "print(indexes)\n",
    "test = np.zeros((32,)+(299,299,3))\n",
    "print(np.shape(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001_0071.jpg', '001_0072.jpg', '001_0073.jpg', '001_0074.jpg', '001_0075.jpg', '001_0076.jpg', '001_0077.jpg', '001_0078.jpg', '002_0001.jpg', '002_0002.jpg', '002_0003.jpg', '002_0004.jpg', '002_0005.jpg', '002_0006.jpg', '002_0007.jpg', '002_0008.jpg', '002_0009.jpg', '002_0010.jpg', '002_0011.jpg', '002_0012.jpg', '002_0013.jpg', '002_0014.jpg', '002_0015.jpg', '002_0016.jpg', '002_0017.jpg', '002_0018.jpg', '002_0019.jpg', '002_0020.jpg', '002_0021.jpg', '002_0022.jpg', '002_0023.jpg', '002_0024.jpg'] [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "# readimages(data_dir)\n",
    "# print(len(train_data), len(train_labels))\n",
    "# for i in range(90,110):\n",
    "#     print (train_data[i],train_labels[i] )\n",
    "\n",
    "# M = pd.DataFrame(train_metadata)\n",
    "# M.columns = ['directory', 'img_name', 'height', 'width', 'channels', 'byte_size', 'bit_depth']\n",
    "\n",
    "# M['category_name'] = M.directory.apply(lambda x: x.split('.')[-1].lower())\n",
    "# M['img_extension'] = M.img_name.apply(lambda x: x.split('.')[-1])\n",
    "# M['category_number'] = M.directory.apply(lambda x: int(x.split('.')[0]))\n",
    "\n",
    "# # remove '101' from some category names\n",
    "# M.category_name = M.category_name.apply(lambda x: x[:-4] if '101' in x else \n",
    "print(train_data[70:102],train_labels[70:102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readimages():\n",
    "\t'''\n",
    "\tGoes through every image and gets the image, putting them into an array\n",
    "\tArgs:\n",
    "\t\tNone\n",
    "\tReturns:\n",
    "\t\tdata: array of information including:\n",
    "\t\t\timage: string\n",
    "\t\t\tshape: int \n",
    "\t\t\tlabel: index from 0 to 256 for the classes\n",
    "\t'''\n",
    "\tdata = []\n",
    "\tj = 0\n",
    "\tobject_dir = os.path.join(main_dir, '256_ObjectCategories')\n",
    "\tobjectCategories = os.listdir(object_dir)\n",
    "\tfor i in range(len(objectCategories)):\n",
    "\t\tlabel = i\n",
    "\t\texamp_dir = os.path.join(object_dir, objectCategories[i])\n",
    "\t\texamples = os.listdir(examp_dir)\n",
    "\t\tprint 'compiling data: %d/%d'%(i+1, len(objectCategories))\n",
    "\t\tfor examp in examples:\n",
    "\t\t\timage_dir = os.path.join(examp_dir, examp)\n",
    "\t\t\timage, shape = get_image(image_dir)\n",
    "\t\t\ttry:\n",
    "\t\t\t\tdata[j]\n",
    "\t\t\texcept IndexError:\n",
    "\t\t\t\tdata.append([])\n",
    "\n",
    "\t\t\tdata[j].append([image, shape, label])\n",
    "\t\t\tj = (j+1)%num_tffile\n",
    "\treturn data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
